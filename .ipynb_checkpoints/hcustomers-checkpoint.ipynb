{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc45fa4",
   "metadata": {},
   "source": [
    "# Happy Costumers\n",
    "@author: Talardia Gbangou, August 2022\n",
    "\n",
    "We want to predict (accuracy score >=73%) if a customer is happy or not based on the answers they give to questions asked. This is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398dc2e",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "620afa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c48fe1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c91825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ACME-HappinessSurvey2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f365d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2  X3  X4  X5  X6\n",
       "0  0   3   3   3   4   2   4\n",
       "1  0   3   2   3   5   4   3\n",
       "2  1   5   3   3   3   3   5\n",
       "3  0   5   4   3   3   3   5\n",
       "4  0   5   4   3   3   3   5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36572b1d",
   "metadata": {},
   "source": [
    "Dara description:\n",
    "\n",
    "Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "\n",
    "X1 = my order was delivered on time\n",
    "\n",
    "X2 = contents of my order was as I expected\n",
    "\n",
    "X3 = I ordered everything I wanted to order\n",
    "\n",
    "X4 = I paid a good price for my order\n",
    "\n",
    "X5 = I am satisfied with my courier\n",
    "\n",
    "X6 = the app makes ordering easy for me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bdc85",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6325b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Y       126 non-null    int64\n",
      " 1   X1      126 non-null    int64\n",
      " 2   X2      126 non-null    int64\n",
      " 3   X3      126 non-null    int64\n",
      " 4   X4      126 non-null    int64\n",
      " 5   X5      126 non-null    int64\n",
      " 6   X6      126 non-null    int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 7.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b76523",
   "metadata": {},
   "source": [
    "we have only numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755205f3",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "Let's check if there is are missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab846237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y     0\n",
       "X1    0\n",
       "X2    0\n",
       "X3    0\n",
       "X4    0\n",
       "X5    0\n",
       "X6    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37179e2",
   "metadata": {},
   "source": [
    "Result show that there are no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45f272",
   "metadata": {},
   "source": [
    "Looking at data description, we have only numerical features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8822747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Y', ylabel='count'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Y',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83fcefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentage = pd.DataFrame(df.Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c387a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentage['Percentage (%)'] = (df_percentage['Y']/df_percentage['Y'].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d400e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>54.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>45.238095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y  Percentage (%)\n",
       "1  69       54.761905\n",
       "0  57       45.238095"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e0753",
   "metadata": {},
   "source": [
    "This visualization and percentage statistic show that we have globally more happy customers(1) than unhappy ones(0). We also have balanced data because the difference in count is not much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0be55",
   "metadata": {},
   "source": [
    "# Building and choice of classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9a48f",
   "metadata": {},
   "source": [
    "importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5ccdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install lightgbm\n",
    "#conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a5258d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ea97e",
   "metadata": {},
   "source": [
    "## Overview of several classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcfe9d",
   "metadata": {},
   "source": [
    "The entire independent and dependent datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b388be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"Y\",axis=1) #features or independent variable\n",
    "y=df[\"Y\"] #target or dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e9826",
   "metadata": {},
   "source": [
    "Checking accuracy of the entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c29b14d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "The entire data accuracy of the model is:  57.936507936507944 %\n",
      "Random Forest Model:\n",
      "The entire data accuracy accuracy of the model is:  94.44444444444444 %\n",
      "Support Vector Machine (SVM) Model :\n",
      "The entire data accuracy of the model is:  73.80952380952381 %\n",
      "Decision tree model :\n",
      "The entire data accuracy of the model is:  94.44444444444444 %\n",
      "Gradientboost model :\n",
      "The entire data accuracy of the model is:  88.88888888888889 %\n",
      "Xgboost model:\n",
      "The entire data accuracy of the model is:  93.65079365079364 %\n",
      "LGBM model:\n",
      "The entire data accuracy of the model is:  76.98412698412699 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Model:\")\n",
    "logmodel = LogisticRegression(random_state=20)\n",
    "logmodel.fit(X,y)\n",
    "predictions_logistic = logmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_logistic, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Random Forest Model:\")\n",
    "rforestmodel =  RandomForestClassifier(random_state=20)\n",
    "rforestmodel.fit(X,y)\n",
    "predictions_rforest = rforestmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_rforest, y)\n",
    "print(\"The entire data accuracy accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Support Vector Machine (SVM) Model :\")\n",
    "svmmodel = svm.SVC(random_state=20)\n",
    "svmmodel.fit(X,y)\n",
    "predictions_svm = svmmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_svm, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Decision tree model :\")\n",
    "dtreemodel = DecisionTreeClassifier(random_state=20)\n",
    "dtreemodel.fit(X,y)\n",
    "predictions_dtree = dtreemodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_dtree, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Gradientboost model :\")\n",
    "gboostmodel = GradientBoostingClassifier(random_state=20)\n",
    "gboostmodel.fit(X,y)\n",
    "predictions_gboost = gboostmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_gboost, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Xgboost model:\")\n",
    "xgbmodel = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20)\n",
    "xgbmodel.fit(X,y)\n",
    "predictions_xgb = xgbmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_xgb, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"LGBM model:\")\n",
    "lgbmmodel = LGBMClassifier(random_state=20)\n",
    "lgbmmodel.fit(X,y)\n",
    "predictions_lgbm = lgbmmodel.predict(X)\n",
    "accuracy = accuracy_score(predictions_lgbm, y)\n",
    "print(\"The entire data accuracy of the model is: \", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861516f",
   "metadata": {},
   "source": [
    "Checking the test accuracy: Train test split of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e7f15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2007a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 6)\n",
      "(88,)\n",
      "(38, 6)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "573b901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9cd078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean test accuracy for logistic regression is:  53.19999999999999 %\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression(random_state=20)\n",
    "scores_logmodel = cross_validate(logmodel, X, y, cv=5)\n",
    "scores_logmodel\n",
    "print(\"The mean test accuracy for logistic regression is: \", scores_logmodel['test_score'].mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83959431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean test accuracy for rforestmodel is:  52.36923076923077 %\n"
     ]
    }
   ],
   "source": [
    "rforestmodel =  RandomForestClassifier(random_state=20)\n",
    "scores_rforestmodel= cross_validate(rforestmodel, X, y, cv=5)\n",
    "scores_rforestmodel\n",
    "print(\"The mean test accuracy for rforestmodel is: \", scores_rforestmodel['test_score'].mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3d6320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean test accuracy for xgbmodel is:  57.10769230769232 %\n"
     ]
    }
   ],
   "source": [
    "xgbmodel = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20)\n",
    "scores_xgbmodel= cross_validate(xgbmodel, X, y, cv=5)\n",
    "scores_xgbmodel\n",
    "print(\"The mean test accuracy for xgbmodel is: \", scores_xgbmodel['test_score'].mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d8e2792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean test accuracy for lgbmmodel is:  60.369230769230775 %\n"
     ]
    }
   ],
   "source": [
    "lgbmmodel = LGBMClassifier(random_state=20)\n",
    "scores_lgbmmodel= cross_validate(lgbmmodel, X, y, cv=5)\n",
    "scores_lgbmmodel\n",
    "print(\"The mean test accuracy for lgbmmodel is: \", scores_lgbmmodel['test_score'].mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6f2fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "The training accuracy of the model is:  65.9090909090909 %\n",
      "Random Forest Model:\n",
      "The training accuracy of the model is:  96.5909090909091 %\n",
      "Support Vector Machine (SVM) Model :\n",
      "The training accuracy of the model is:  72.72727272727273 %\n",
      "Decision tree model :\n",
      "The training accuracy of the model is:  96.5909090909091 %\n",
      "Gradientboost model :\n",
      "The training accuracy of the model is:  94.31818181818183 %\n",
      "Xgboost model:\n",
      "The training accuracy of the model is:  92.04545454545455 %\n",
      "LGBM model:\n",
      "The training accuracy of the model is:  72.72727272727273 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Model:\")\n",
    "logmodel = LogisticRegression(random_state=20)\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions_logistic = logmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_logistic, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Random Forest Model:\")\n",
    "rforestmodel =  RandomForestClassifier(random_state=20)\n",
    "rforestmodel.fit(X_train,y_train)\n",
    "predictions_rforest = rforestmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_rforest, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Support Vector Machine (SVM) Model :\")\n",
    "svmmodel = svm.SVC(random_state=20)\n",
    "svmmodel.fit(X_train,y_train)\n",
    "predictions_svm = svmmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_svm, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Decision tree model :\")\n",
    "dtreemodel = DecisionTreeClassifier(random_state=20)\n",
    "dtreemodel.fit(X_train,y_train)\n",
    "predictions_dtree = dtreemodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_dtree, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Gradientboost model :\")\n",
    "gboostmodel = GradientBoostingClassifier(random_state=20)\n",
    "gboostmodel.fit(X_train,y_train)\n",
    "predictions_gboost = gboostmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_gboost, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Xgboost model:\")\n",
    "xgbmodel = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20)\n",
    "xgbmodel.fit(X_train,y_train)\n",
    "predictions_xgb = xgbmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_xgb, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"LGBM model:\")\n",
    "lgbmmodel = LGBMClassifier(random_state=20)\n",
    "lgbmmodel.fit(X_train,y_train)\n",
    "predictions_lgbm = lgbmmodel.predict(X_train)\n",
    "accuracy = accuracy_score(predictions_lgbm, y_train)\n",
    "print(\"The training accuracy of the model is: \", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ef74a",
   "metadata": {},
   "source": [
    "The accuracy of the entire data and the training data are close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfb6c2",
   "metadata": {},
   "source": [
    "Defining and testing four classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21258f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "The validation/test accuracy of the model is:  57.89473684210527 %\n",
      "Random Forest Model:\n",
      "The validation/test accuracy of the model is:  60.526315789473685 %\n",
      "Support Vector Machine (SVM) Model :\n",
      "The validation/test of the model is:  57.89473684210527 %\n",
      "Decision tree model :\n",
      "The validation/test of the model is:  57.89473684210527 %\n",
      "Gradientboost model :\n",
      "The validation/test of the model is:  68.42105263157895 %\n",
      "Xgboost model:\n",
      "The validation/test of the model is:  65.78947368421053 %\n",
      "LGBM model:\n",
      "The validation/test of the model is:  63.1578947368421 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Model:\")\n",
    "logmodel = LogisticRegression(random_state=20)\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions_logistic = logmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_logistic, y_val)\n",
    "print(\"The validation/test accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Random Forest Model:\")\n",
    "rforestmodel =  RandomForestClassifier(random_state=20)\n",
    "rforestmodel.fit(X_train,y_train)\n",
    "predictions_rforest = rforestmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_rforest, y_val)\n",
    "print(\"The validation/test accuracy of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Support Vector Machine (SVM) Model :\")\n",
    "svmmodel = svm.SVC(random_state=20)\n",
    "svmmodel.fit(X_train,y_train)\n",
    "predictions_svm = svmmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_svm, y_val)\n",
    "print(\"The validation/test of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Decision tree model :\")\n",
    "dtreemodel = DecisionTreeClassifier(random_state=20)\n",
    "dtreemodel.fit(X_train,y_train)\n",
    "predictions_dtree = dtreemodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_dtree, y_val)\n",
    "print(\"The validation/test of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Gradientboost model :\")\n",
    "gboostmodel = GradientBoostingClassifier(random_state=20)\n",
    "gboostmodel.fit(X_train,y_train)\n",
    "predictions_gboost = gboostmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_gboost, y_val)\n",
    "print(\"The validation/test of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"Xgboost model:\")\n",
    "xgbmodel = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20)\n",
    "xgbmodel.fit(X_train,y_train)\n",
    "predictions_xgb = xgbmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_xgb, y_val)\n",
    "print(\"The validation/test of the model is: \", accuracy*100, \"%\")\n",
    "\n",
    "print(\"LGBM model:\")\n",
    "lgbmmodel = LGBMClassifier(random_state=20)\n",
    "lgbmmodel.fit(X_train,y_train)\n",
    "predictions_lgbm = lgbmmodel.predict(X_val)\n",
    "accuracy = accuracy_score(predictions_lgbm, y_val)\n",
    "print(\"The validation/test of the model is: \", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194ac9a",
   "metadata": {},
   "source": [
    "Evaluation of accuracy of different models with (1) the entire data, (2) the training data and (3) the test data show that Random Forest and Xgboost model have the highess scores in all three situation. However, we have an overfiting clearly and problem on these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9caded1",
   "metadata": {},
   "source": [
    "## Tunning selected models parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecfdab",
   "metadata": {},
   "source": [
    "Set up a hyper parameter grid for a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8d7d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_rf={\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['auto', 'sqrt','log2'],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'criterion': ['gini','entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50655edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "884a86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the param grid\n",
    "#params_grid_rf = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    "#               'max_depth': max_depth,\n",
    "#               'min_samples_split': min_samples_split,\n",
    "#               'min_samples_leaf': min_samples_leaf,\n",
    "#               'bootstrap': bootstrap}\n",
    "#print(params_grid_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94262db8",
   "metadata": {},
   "source": [
    "Create the grid search object for random forest and fit it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7de9dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=20), n_jobs=4,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 5, 10],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid=GridSearchCV(RandomForestClassifier(random_state=20),params_grid_rf,scoring=\"accuracy\",cv=5,verbose=1,n_jobs = 4)\n",
    "#rf_grid=RandomizedSearchCV(RandomForestClassifier(random_state=20),params_grid_rf,scoring=\"accuracy\",cv=5,verbose=1,n_jobs = 4)\n",
    "rf_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871aa37",
   "metadata": {},
   "source": [
    "Get the best parameters for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a998b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bd7a8",
   "metadata": {},
   "source": [
    "Fitting with best parameter on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_param=rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9db4b",
   "metadata": {},
   "source": [
    "Evaluation of the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a823ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainning accuracy of the random forest model is:  96.5909090909091 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_rf=rf_best_param.predict(X_train)\n",
    "print(\"The trainning accuracy of the random forest model is: \", accuracy_score(y_train,y_train_pred_rf)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87610d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation or test accuracy of the random forest model is:  60.526315789473685 %\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_rf=rf_best_param.predict(X_val)\n",
    "print(\"The validation or test accuracy of the random forest model is: \", accuracy_score(y_val,y_val_pred_rf)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1a4a9",
   "metadata": {},
   "source": [
    "The train and validation accuracies are reducing after hyperparameters tunning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e717df3",
   "metadata": {},
   "source": [
    "Set up a hyper parameter grid for xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "078a1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdcfc5",
   "metadata": {},
   "source": [
    "Create the grid search object for xgboost and fit it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7e6873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='mlogloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, mon...\n",
       "                                     random_state=20, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8],\n",
       "                         'max_depth': [15, 20, 25],\n",
       "                         'n_estimators': [50, 100, 150],\n",
       "                         'reg_alpha': [1.1, 1.2, 1.3],\n",
       "                         'reg_lambda': [1.1, 1.2, 1.3],\n",
       "                         'subsample': [0.7, 0.8, 0.9]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid=GridSearchCV(XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20),params_grid_xgb,scoring=\"accuracy\",cv=5,verbose=1)\n",
    "xgb_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5b1f9",
   "metadata": {},
   "source": [
    "Get the best parameters for xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7e3b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'max_depth': 15,\n",
       " 'n_estimators': 100,\n",
       " 'reg_alpha': 1.3,\n",
       " 'reg_lambda': 1.1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32246927",
   "metadata": {},
   "source": [
    "Fitting with best parameter on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_param=xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c74b58",
   "metadata": {},
   "source": [
    "Evaluation of the xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03a53693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainning accuracy of the Xgboost model is:  82.95454545454545 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb=xgb_best_param.predict(X_train)\n",
    "print(\"The trainning accuracy of the Xgboost model is: \", accuracy_score(y_train,y_train_pred_xgb)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d31a9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test/validation accuracy of the Xgboost model is:  65.78947368421053 %\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_xgb=xgb_best_param.predict(X_val)\n",
    "print(\"The test/validation accuracy of the Xgboost model is: \", accuracy_score(y_val,y_val_pred_xgb)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa9b0df",
   "metadata": {},
   "source": [
    "The train and validation accuracy are reducing after hyperparameters tunning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dfeb6",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb86760",
   "metadata": {},
   "source": [
    "Random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bfe1c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.14274\n",
      "Feature: 1, Score: 0.19177\n",
      "Feature: 2, Score: 0.21224\n",
      "Feature: 3, Score: 0.17958\n",
      "Feature: 4, Score: 0.16762\n",
      "Feature: 5, Score: 0.10605\n"
     ]
    }
   ],
   "source": [
    "importance = rf_best_param.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "  print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "#print(rforestmodel.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd83c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf_best_param)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, features=X, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae6faa",
   "metadata": {},
   "source": [
    "Xgb feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92abc2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, eval_metric='mlogloss', gamma=0,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=20, reg_alpha=1.3, reg_lambda=1.1,\n",
       "              scale_pos_weight=1, subsample=0.7, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model=XGBClassifier(eval_metric='mlogloss',\n",
    "                             use_label_encoder=False,\n",
    "                             random_state=20, \n",
    "                             colsample_bytree=0.7,\n",
    "                             max_depth=15,\n",
    "                             n_estimators=100,\n",
    "                             reg_alpha=1.3,\n",
    "                             reg_lambda=1.1,\n",
    "                             subsample= 0.7)\n",
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3811a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.29194\n",
      "Feature: 1, Score: 0.16421\n",
      "Feature: 2, Score: 0.12979\n",
      "Feature: 3, Score: 0.15841\n",
      "Feature: 4, Score: 0.16300\n",
      "Feature: 5, Score: 0.09265\n"
     ]
    }
   ],
   "source": [
    "importance = xgb_best_param.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "  print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "#print(rforestmodel.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = rf_best_param.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "  print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "#print(rforestmodel.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2321ebf",
   "metadata": {},
   "source": [
    "THe barplots show the order of features importance for the random forest Xgboost models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141324f8",
   "metadata": {},
   "source": [
    "## Random Forest Model evaluation after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "18cd71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat1 =['X1','X2','X5']\n",
    "#selected_feat =['X2','X3','X4','X5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e1f01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[selected_feat1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d9737629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=20)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf_best_param= RandomForestClassifier(random_state=20,max_depth=4,max_features = 'auto', n_estimators= 48,\n",
    "#                                     min_samples_leaf=2,min_samples_split=2,bootstrap =True)\n",
    "rf_best_param=RandomForestClassifier(random_state=20,criterion = 'gini',max_depth=10,max_features = 'auto', n_estimators= 100)\n",
    "rf_best_param.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2ce4e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainning accuracy of the random forest model after feature selection is:  82.0 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_rf=rf_best_param.predict(X_train)\n",
    "print(\"The trainning accuracy of the random forest model after feature selection is: \", accuracy_score(y_train,y_train_pred_rf)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ea0fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation or test accuracy of the random forest model after feature selection is:  65.38461538461539 %\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_rf=rf_best_param.predict(X_val)\n",
    "print(\"The validation or test accuracy of the random forest model after feature selection is: \", accuracy_score(y_val,y_val_pred_rf)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d070788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fcbb643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy matrix random forest=\n",
      "[[ 6  5]\n",
      " [ 4 11]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy matrix random forest=\")\n",
    "print(confusion_matrix(y_val,y_val_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "417c28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report random forest=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.57        11\n",
      "           1       0.69      0.73      0.71        15\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.64      0.64      0.64        26\n",
      "weighted avg       0.65      0.65      0.65        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report random forest=\")\n",
    "print(classification_report(y_val,y_val_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7ec66",
   "metadata": {},
   "source": [
    "## Xgboost Model evaluation after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "77267708",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat2 =['X1','X2','X4','X5']\n",
    "#selected_feat2 =['X1','X3','X4','X5']\n",
    "X2 = X[selected_feat2]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X2, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd1842bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, eval_metric='mlogloss', gamma=0,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=20, reg_alpha=1.3, reg_lambda=1.1,\n",
       "              scale_pos_weight=1, subsample=0.7, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best_param=XGBClassifier(eval_metric='mlogloss',\n",
    "                             use_label_encoder=False,\n",
    "                             random_state=20, \n",
    "                             colsample_bytree=0.7,\n",
    "                             max_depth=15,\n",
    "                             n_estimators=100,\n",
    "                             reg_alpha=1.3,\n",
    "                             reg_lambda=1.1,\n",
    "                             subsample= 0.7)\n",
    "xgb_best_param.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7d80884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainning accuracy of the Xgboost model after feature selection is:  75.0 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb=xgb_best_param.predict(X_train)\n",
    "print(\"The trainning accuracy of the Xgboost model after feature selection is: \", accuracy_score(y_train,y_train_pred_xgb)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1a1898bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheThe test/validation of the Xgboost model after feature selection is:  65.38461538461539 %\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_xgb=xgb_best_param.predict(X_val)\n",
    "print(\"TheThe test/validation of the Xgboost model after feature selection is: \", accuracy_score(y_val,y_val_pred_xgb)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79964582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy matrix Xgboost model=\n",
      "[[ 5  6]\n",
      " [ 3 12]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy matrix Xgboost model=\")\n",
    "print(confusion_matrix(y_val,y_val_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d56b06b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report Xgboost model=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.53        11\n",
      "           1       0.67      0.80      0.73        15\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.65      0.63      0.63        26\n",
      "weighted avg       0.65      0.65      0.64        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report Xgboost model=\")\n",
    "print(classification_report(y_val,y_val_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822415b",
   "metadata": {},
   "source": [
    "Conclusion: We can predict with an accuracy of 73% if a customer is happy or not using the random model (with the best parameters specified above) and keeping all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68715d4b",
   "metadata": {},
   "source": [
    "## Testing cross-validation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "38255f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c238209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean test accuracy for logistic regression is:  52.368951612903224 %\n",
      "The mean test accuracy for rforestmodel is:  52.368951612903224 %\n",
      "The mean test accuracy for xgbmodel is:  56.30040322580645 %\n",
      "The mean test accuracy for lgbmmodel is:  62.67641129032258 %\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression(random_state=20)\n",
    "scores_logmodel = cross_validate(logmodel, X, y, cv=4)\n",
    "scores_logmodel\n",
    "print(\"The mean test accuracy for logistic regression is: \", scores_logmodel['test_score'].mean()*100, \"%\")\n",
    "\n",
    "rforestmodel =  RandomForestClassifier(random_state=20)\n",
    "scores_rforestmodel= cross_validate(rforestmodel, X, y, cv=4)\n",
    "scores_rforestmodel\n",
    "print(\"The mean test accuracy for rforestmodel is: \", scores_rforestmodel['test_score'].mean()*100, \"%\")\n",
    "\n",
    "xgbmodel = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False,random_state=20)\n",
    "scores_xgbmodel= cross_validate(xgbmodel, X, y, cv=4)\n",
    "scores_xgbmodel\n",
    "print(\"The mean test accuracy for xgbmodel is: \", scores_xgbmodel['test_score'].mean()*100, \"%\")\n",
    "\n",
    "lgbmmodel = LGBMClassifier(random_state=20)\n",
    "scores_lgbmmodel= cross_validate(lgbmmodel, X, y, cv=4)\n",
    "scores_lgbmmodel\n",
    "print(\"The mean test accuracy for lgbmmodel is: \", scores_lgbmmodel['test_score'].mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
